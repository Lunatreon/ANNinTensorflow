{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we take a step back\n",
    "We will watch at functions of tensorflow, which will help us :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how you like the final topic project about: how to optimize training with gans?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã®mport tesn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "sample_input = tf.random.uniform(shape=(4,2), minval=-3,maxval=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.6738518  0.9387714 ]\n",
      " [0.14364387 0.83773047]\n",
      " [0.4468105  0.09600986]\n",
      " [0.52505213 0.81481093]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#@ is a decorator -> read the documentation \n",
    "#add a functionality to a object?\n",
    "@tf.custom_gradient\n",
    "def my_sigmoid(x):\n",
    "    sig_res = 1/(1+tf.exp(-x))\n",
    "    def grad(upstream):\n",
    "        diag_of_jacobian = sig_res * (1 - sig_res)\n",
    "        downstream = upstream*diag_of_jacobian\n",
    "        return downstream\n",
    "    return sig_res, grad\n",
    "\n",
    "print (my_sigmoid(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.7256584  2.7299585 ]\n",
      " [0.         1.6414375 ]\n",
      " [0.         0.        ]\n",
      " [0.10029244 1.4815788 ]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.custom_gradient\n",
    "def my_relu(x):\n",
    "    #relu_res = tf.math.maximum(0,x)\n",
    "    relu_res = tf.where(x>0,x,tf.zeros_like(x))\n",
    "    def grad(upstream):\n",
    "        #downstream = tf.where([x < 0, x > 0]).numpy() * upstream\n",
    "        d_dx= tf.where(x>0, tf.ones_like(x),tf.zeros_like(x))\n",
    "        downstream = upstream*d_dx\n",
    "        return downstream\n",
    "    return relu_res, grad\n",
    "\n",
    "print (my_relu(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
      "array([[1., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 0.],\n",
      "       [1., 1.]], dtype=float32)>] [<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
      "array([[1., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 0.],\n",
      "       [1., 1.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "sample_input = tf.Variable(initial_value=sample_input)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tf_relu_act = tf.nn.relu(sample_input)\n",
    "    my_relu_act = my_relu(sample_input)\n",
    "grads_tf_relu = tape.gradient(tf_relu_act, [sample_input])\n",
    "grads_own_relu = tape.gradient(my_relu_act, [sample_input])\n",
    "del tape\n",
    "\n",
    "print (grads_own_relu, grads_tf_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marce\\Documents\\GitHub\\ANNinTensorflow\\FlipClassroom\\fourthClassroom.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marce/Documents/GitHub/ANNinTensorflow/FlipClassroom/fourthClassroom.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         res\u001b[39m.\u001b[39mappend(grads_tf_relu)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marce/Documents/GitHub/ANNinTensorflow/FlipClassroom/fourthClassroom.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m some_tf_loop()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/marce/Documents/GitHub/ANNinTensorflow/FlipClassroom/fourthClassroom.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m (res[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mnumpy())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "#tf function will speed up code but it must be tf code (and not python)\n",
    "sample_input = tf.Variable(initial_value=tf.random.uniform(shape=(10,4,3)))\n",
    "@tf.function\n",
    "def some_tf_loop():\n",
    "    for step in range(10):\n",
    "        inputs = sample_input[step,:,:]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tf_relu_act = tf.nn.relu(sample_input)\n",
    "        grads_tf_relu = tape.gradient(tf_relu_act, [sample_input])\n",
    "        res.append(grads_tf_relu)\n",
    "\n",
    "\n",
    "some_tf_loop()\n",
    "print (res[0].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
