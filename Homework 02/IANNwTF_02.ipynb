{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 14:59:12.680314: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 14:59:12.749494: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 14:59:12.750895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 14:59:18.090962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 15:30:15.012917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-26 15:30:15.013608: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ds):\n",
    "\n",
    "    #data prep\n",
    "    #ds = tfds.load('mnist', split='train')\n",
    "\n",
    "    #train_ds = train_ds.map(lambda feature_dict: feature_dict['image'], feature=['label'])\n",
    "    ds = ds.map(lambda image, label: (tf.reshape(image,(-1,)), label))\n",
    "    ds = ds.map(lambda image, label: ((tf.cast(image,tf.float32)/128)-1, label))\n",
    "    ds = ds.map(lambda image, label: (image, tf.one_hot(label, depth= 10)))\n",
    "    ds = ds.shuffle(1024).batch(128)\n",
    "    ds = ds.prefetch(4)\n",
    "\n",
    "    # for x,y in ds.take(1):\n",
    "    #     print(x,y)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds), ds_info = tfds.load('mnist', split=['train','test'],as_supervised=True, with_info=True)\n",
    "\n",
    "tfds.show_examples(train_ds, ds_info)\n",
    "\n",
    "train_ds = prepare_data(train_ds)\n",
    "test_ds = prepare_data(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Creation via Subclassing from tf.keras.Model\n",
    "class MLP_Model(tf.keras.Model):\n",
    "    def __init__ (self, layer_sizes, output_size=10):\n",
    "        super().__init__()\n",
    "        self.mlp_layers = []\n",
    "        #layer_sizes e. g. [256,256]\n",
    "        for layer_size in layer_sizes:\n",
    "            new_layer = tf.keras.layers.Dense(units = layer_size, activation='sigmoid')\n",
    "            self.mlp_layers.append(new_layer)\n",
    "        self.output_layer = tf.keras.layers.Dense(units = output_size, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.mlp_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model.call(x)\n",
    "        loss = loss_func(target, pred)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.variables))\n",
    "    return loss.numpy()\n",
    "\n",
    "def test(model, test_data, loss_function):\n",
    "    # test over complete test data\n",
    "    test_accuracy_aggregator = []\n",
    "    test_loss_aggregator = []\n",
    "\n",
    "    for (input, target) in test_data:\n",
    "        prediction = model(input)\n",
    "        sample_test_loss = loss_function(target, prediction)\n",
    "        sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
    "        test_loss_aggregator.append(np.mean(sample_test_loss))\n",
    "        test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "\n",
    "    test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "    test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
    "\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs, model, training_ds, test_ds, loss_func, optimizer):\n",
    "    epoch_losses = []\n",
    "    epoch_test_loss= []\n",
    "    epoch_test_accuracies = []\n",
    "    for epoch in range( epochs):\n",
    "        losses = []\n",
    "        for x, target in training_ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = model.call(x)\n",
    "                loss = loss_func(target, pred)\n",
    "\n",
    "            gradients = tape.gradient(loss, model.variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.variables))\n",
    "            losses.append(loss.numpy())\n",
    "        epoch_losses.append(tf.reduce_mean(losses))\n",
    "\n",
    "        test_loss, test_accuracy = test (model, test_ds, loss_func)\n",
    "        epoch_test_loss.append(test_loss)\n",
    "        epoch_test_accuracies.append(test_accuracy)\n",
    "    return epoch_losses, epoch_test_loss, epoch_test_accuracies\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model\n",
    "tf.keras.backend.clear_session()\n",
    "epochs = 10\n",
    "model = MLP_Model(layer_sizes=(256,256))\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.02)\n",
    "\n",
    "train_losses, test_losses, test_accuracies = training(epochs=epochs, model=model,training_ds=train_ds,test_ds=test_ds, loss_func=cce, optimizer=optimizer)\n",
    "plotting[\"basic\"] = [train_losses, test_losses, test_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model other optimizer\n",
    "tf.keras.backend.clear_session()\n",
    "epochs = 10\n",
    "model = MLP_Model(layer_sizes=(256,256))\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.002)\n",
    "\n",
    "train_losses, test_losses, test_accuracies = training(epochs=epochs, model=model,training_ds=train_ds,test_ds=test_ds, loss_func=cce, optimizer=optimizer)\n",
    "plotting[\"adam optimizer\"] = [train_losses, test_losses, test_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. more epochs\n",
    "tf.keras.backend.clear_session()\n",
    "epochs = 30\n",
    "model = MLP_Model(layer_sizes=(256,256))\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.02)\n",
    "\n",
    "train_losses, test_losses, test_accuracies = training(epochs=epochs, model=model,training_ds=train_ds,test_ds=test_ds, loss_func=cce, optimizer=optimizer)\n",
    "plotting[\"more epochs\"] = [train_losses, test_losses, test_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. higher learning rate\n",
    "tf.keras.backend.clear_session()\n",
    "epochs = 10\n",
    "model = MLP_Model(layer_sizes=(256,256))\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.04)\n",
    "\n",
    "train_losses, test_losses, test_accuracies = training(epochs=epochs, model=model,training_ds=train_ds,test_ds=test_ds, loss_func=cce, optimizer=optimizer)\n",
    "plotting[\"higher learningrate\"] = [train_losses, test_losses, test_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. more layers\n",
    "tf.keras.backend.clear_session()\n",
    "epochs = 20\n",
    "model = MLP_Model(layer_sizes=(256,256,128))\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.02)\n",
    "\n",
    "train_losses, test_losses, test_accuracies = training(epochs=epochs, model=model,training_ds=train_ds,test_ds=test_ds, loss_func=cce, optimizer=optimizer)\n",
    "plotting[\"more layers\"] = [train_losses, test_losses, test_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. viewer units per layer\n",
    "tf.keras.backend.clear_session()\n",
    "epochs = 10\n",
    "model = MLP_Model(layer_sizes=(128,128))\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.02)\n",
    "\n",
    "train_losses, test_losses, test_accuracies = training(epochs=epochs, model=model,training_ds=train_ds,test_ds=test_ds, loss_func=cce, optimizer=optimizer)\n",
    "plotting[\"fewer units\"] = [train_losses, test_losses, test_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "for ax, key in zip(axs.flat, plotting.keys()):\n",
    "    \n",
    "    train_losses, test_losses, test_accuracies = plotting[key]\n",
    "    \n",
    "    line1, = ax.plot(train_losses)\n",
    "    line2, = ax.plot(test_losses)\n",
    "    line3, = ax.plot(test_accuracies)\n",
    "    ax.legend((line1,line2, line3),(\"training\",\"test\", \"test accuracy\"))\n",
    "    ax.set_title(key)\n",
    "    ax.set(xlabel=\"Training steps\", ylabel=\"Loss/Accuracy\")\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
